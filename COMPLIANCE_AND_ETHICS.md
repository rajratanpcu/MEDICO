# Medical AI Compliance & Ethics Guide
> **Subject**: Safety, Ethics, and Data Privacy  
> **Audience**: Examiners / System Auditors  
> **Author**: Antigravity (Compliance Officer)

## 1. Ethical Boundaries (The "Rules of Engagement")

### A. Non-Diagnostic Principle
The AI is a **Notification & Summary Engine**, not a Diagnostic Tool.
*   **Allowed**: "The report mentions 'Arhythmia'." (Extraction)
*   **Prohibited**: "You have Arhythmia." (Diagnosis)
*   **Prohibited**: "You should take Aspirin." (Prescription)

### B. Human-in-the-Loop (HITL)
No critical action (Delete Record, Send Prescription, Notify Emergency) occurs without human confirmation or pre-authorization.
*   *Implementation*: The Voice Assistant prepares the action and asks, "I have prepared the email. Say 'Send' to confirm."

### C. Bias Awareness
We acknowledge that AI models (LLMs) may have biases based on training data. We mitigate this by using RAG (Retrieval Augmented Generation) to ground answers in *provided* medical reports rather than general internet knowledge.

---

## 2. Disclaimer Text Examples

Hardcode these into the UI and Voice Responses.

### Top of Chat / Voice Banner
> "⚠️ **Investigational Device**: This system is for educational and administrative assistance only. It does not provide medical advice or diagnosis. Always verify with a certified physician."

### Voice Response to Symptoms
> "I can listen to your symptoms for documentation, but I cannot diagnose you. If this is an emergency, please hang up and call 911 immediately."

### Report Analysis Footer
> "**AI Generated Summary**: This text was generated by AI and may contain errors. Please review the original PDF source."

---

## 3. Security Best Practices

### A. Data Minimization (Privacy by Design)
*   **Voice**: Audio blobs are transcribed in memory (RAM) and deleted immediately after text extraction. We do not store patient voice recordings permanently.
*   **Notifications**: SMS/Email alerts reference an ID ("Check Patient #123") rather than sending full PII ("Check John Doe's HIV test") over unencrypted channels.

### B. Role-Based Access Control (RBAC)
*   **Doctor Role**: Read/Write Patient Data, Audit Logs.
*   **Patient Role**: Read Own Data Only. No Write access to Clinical Notes.
*   *Voice Check*: The AI checks `user.role` before executing any `DATA_MODIFICATION` intent.

### C. Audit Trails
Every single AI action is logged in the `system_logs` table:
`[TIMESTAMP] [USER_ID] [INTENT: EMERGENCY] [STATUS: SENT] [CONFIDENCE: 0.98]`

---

## 4. Viva / Defence Talking Points

**Examiner: "Is your AI safe to use in a hospital?"**

**Your Answer**:
"Sir/Ma'am, we designed this system as a **Clinical Decision Support System (CDSS)**, not a replacement for doctors.
1.  **Safety**: We adhere to strict 'Human-in-the-Loop' protocols. The AI never executes critical actions without confirmation.
2.  **Privacy**: We process voice data locally to avoid sending patient audio to third-party clouds, ensuring data sovereignty.
3.  **Transparency**: Every AI output is flagged with a disclaimer, and we maintain a complete audit log of all automated actions for accountability."

**Examiner: "What if the AI hallucinates?"**

**Your Answer**:
"We use RAG (Retrieval Augmented Generation). The AI is instructed to answer *only* based on the context of the specific medical record or report retrieved from our database. If it doesn't know, it is programmed to say 'I don't know' rather than guess."
